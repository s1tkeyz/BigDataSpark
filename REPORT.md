# Инструкция по развертыванию и использованию системы аналитики продаж

## Структура проекта

Проект состоит из нескольких компонентов:
- PostgreSQL база данных со схемой "звезда" (таблицы фактов и измерений)
- Apache Spark для ETL-процесса
- Clickhouse для хранения витрин данных
- Набор SQL-запросов для анализа данных

## Этапы развертывания и использования

### 1. Подготовка окружения

Убедитесь, что у вас установлены:
- Docker
- Docker Compose

### 2. Запуск контейнеров

```bash
# Запуск всех сервисов
docker-compose up -d
```

Это запустит следующие контейнеры:
- PostgreSQL (порт 5432)
- Clickhouse (порты 8123, 9000)
- Spark Master (порт 7077)
- Spark Worker

### 3. Инициализация баз данных

#### 3.1. Инициализация PostgreSQL

```bash
# Создание схемы "звезда" в PostgreSQL
docker exec -i bigdata_database psql -U postgres -d bigdata < database_init/postgres_init.sql

```

Этот шаг создаст следующие таблицы в схеме "звезда":
- Таблица фактов: `f_sales` (продажи)
- Таблицы измерений:
  - `d_products` (товары)
  - `d_customers` (покупатели)
  - `d_dates` (даты)
  - `d_stores` (магазины)
  - `d_suppliers` (поставщики)

#### 3.2. Инициализация Clickhouse

```bash
# Создание схемы в Clickhouse
docker exec -i clickhouse clickhouse-client --user custom_user --password pswd < database_init/clickhouse_init.sql
```

### 4. Запуск ETL-процесса

ETL-процесс выполняется с помощью Apache Spark. Скрипт `create_marts.py` читает данные из PostgreSQL, выполняет необходимые преобразования и записывает результаты в Clickhouse.

```bash
# Запуск ETL-процесса
docker exec spark-worker spark-submit --master spark://spark-master:7077 --jars /opt/spark-apps/jars/postgresql-42.6.0.jar,/opt/spark-apps/jars/clickhouse-jdbc-0.4.6.jar /opt/spark-apps/etl_scripts/create_marts.py
```

### 5. Выполнение аналитических запросов

После успешного выполнения ETL-процесса можно выполнять аналитические запросы из файла `reports.sql`. Файл содержит 10 запросов для анализа различных аспектов продаж:

1. Топ-10 самых продаваемых товаров
2. Топ-10 самых прибыльных товаров
3. Анализ продаж по месяцам с динамикой роста
4. Топ-5 магазинов по обороту
5. Анализ корреляции рейтинга товаров с продажами
6. Топ-10 клиентов по сумме покупок
7. Анализ эффективности поставщиков
8. Категории товаров по популярности
9. География продаж по странам
10. Анализ количества заказов по месяцам

Для выполнения запросов:
```bash
# Подключение к Clickhouse и выполнение запросов
docker exec -i clickhouse clickhouse-client --user custom_user --password pswd < reports.sql
```

## Структура витрин данных

В Clickhouse созданы следующие витрины:

1. `product_sales_mart` - анализ продаж продуктов
2. `customer_sales_mart` - анализ клиентов
3. `time_sales_mart` - временной анализ
4. `store_sales_mart` - анализ магазинов
5. `supplier_sales_mart` - анализ поставщиков
6. `product_quality_mart` - анализ качества продуктов

## Устранение возможных проблем

1. Если возникают проблемы с доступом к файлам в контейнере Spark:
   - Проверьте монтирование томов в `docker-compose.yml`
   - Убедитесь, что пути к JAR-файлам и скриптам корректны

2. Если возникают проблемы с аутентификацией в Clickhouse:
   - Проверьте файл `users.xml` и его монтирование в контейнер
   - Убедитесь, что используются правильные учетные данные (custom_user/pswd)

3. Если ETL-процесс завершается с ошибкой:
   - Проверьте логи контейнера spark-worker
   - Убедитесь, что все необходимые JAR-файлы доступны
   - Проверьте подключение к базам данных PostgreSQL и Clickhouse
